#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø© ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¯Ø±ÙˆØ³
Check for duplicate questions across all lessons
"""

import os
import re
from collections import defaultdict

def extract_questions_from_lesson(file_path):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† Ø¯Ø±Ø³ ÙˆØ§Ø­Ø¯"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¯Ø±Ø³
        title_match = re.search(r'<title>([^<]+)</title>', content)
        lesson_title = title_match.group(1) if title_match else "Ø¯Ø±Ø³ ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙÙŠ JavaScript
        question_pattern = r'\{\s*q:\s*["\']([^"\']+)["\']\s*,\s*c:\s*\[(.*?)\]\s*,\s*a:\s*(\d+)\s*\}'
        question_matches = re.findall(question_pattern, content, re.DOTALL)
        
        questions = []
        for i, (question, choices_str, answer_idx) in enumerate(question_matches, 1):
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ
            clean_question = question.strip()
            questions.append({
                'text': clean_question,
                'number': i,
                'choices': choices_str,
                'answer': answer_idx
            })
        
        return lesson_title, questions
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© {file_path}: {e}")
        return None, []

def find_duplicate_questions():
    """Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø©"""
    
    print("ğŸ”„ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø© ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¯Ø±ÙˆØ³...")
    print("=" * 70)
    
    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¯Ø±ÙˆØ³
    lessons = [
        ("unit-1-cells/lesson-1-1/index.html", "ğŸ”¬ Ø¯Ø±Ø³ 1-1"),
        ("unit-1-cells/lesson-1-2/index.html", "ğŸ§ª Ø¯Ø±Ø³ 1-2"),
        ("unit-1-cells/lesson-1-3/index.html", "ğŸ” Ø¯Ø±Ø³ 1-3"),
        ("unit-2-transport/lesson-2-1/index.html", "ğŸš› Ø¯Ø±Ø³ 2-1"),
        ("unit-2-transport/lesson-2-2/index.html", "ğŸ’§ Ø¯Ø±Ø³ 2-2"),
        ("unit-2-transport/lesson-2-3/index.html", "âš¡ Ø¯Ø±Ø³ 2-3"),
        ("unit-3-biomolecules/lesson-3-1/index.html", "ğŸ§¬ Ø¯Ø±Ø³ 3-1"),
        ("unit-3-biomolecules/lesson-3-2/index.html", "ğŸ§ª Ø¯Ø±Ø³ 3-2"),
        ("unit-3-biomolecules/lesson-3-3/index.html", "âš—ï¸ Ø¯Ø±Ø³ 3-3"),
        ("unit-4-nutrition/lesson-4-1/index.html", "ğŸ Ø¯Ø±Ø³ 4-1"),
        ("unit-4-nutrition/lesson-4-2/index.html", "ğŸ”„ Ø¯Ø±Ø³ 4-2"),
        ("unit-5-respiration/lesson-5-1/index.html", "ğŸ’¨ Ø¯Ø±Ø³ 5-1"),
        ("unit-6-homeostasis/lesson-6-1/index.html", "âš–ï¸ Ø¯Ø±Ø³ 6-1"),
        ("unit-6-homeostasis/lesson-6-2/index.html", "ğŸŒ¡ï¸ Ø¯Ø±Ø³ 6-2"),
        ("unit-6-homeostasis/lesson-6-3/index.html", "ğŸ¬ Ø¯Ø±Ø³ 6-3"),
        ("unit-6-homeostasis/lesson-6-4/index.html", "ğŸ§  Ø¯Ø±Ø³ 6-4")
    ]
    
    # Ù‚Ø§Ù…ÙˆØ³ Ù„ØªØªØ¨Ø¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
    all_questions = {}  # question_text -> [(lesson, question_number), ...]
    lesson_questions = {}  # lesson -> questions
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¯Ø±ÙˆØ³
    for lesson_path, lesson_short_name in lessons:
        if os.path.exists(lesson_path):
            print(f"ğŸ”„ Ù…Ø¹Ø§Ù„Ø¬Ø©: {lesson_short_name}")
            
            title, questions = extract_questions_from_lesson(lesson_path)
            lesson_questions[lesson_short_name] = questions
            
            for q in questions:
                question_text = q['text'].lower().strip()
                if question_text not in all_questions:
                    all_questions[question_text] = []
                all_questions[question_text].append((lesson_short_name, q['number']))
            
            print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(questions)} Ø³Ø¤Ø§Ù„")
        else:
            print(f"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {lesson_path}")
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø©
    duplicates = {}
    similar_questions = {}
    
    for question_text, occurrences in all_questions.items():
        if len(occurrences) > 1:
            duplicates[question_text] = occurrences
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø© (ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ù…Ø´ØªØ±ÙƒØ©)
    question_texts = list(all_questions.keys())
    for i, q1 in enumerate(question_texts):
        for j, q2 in enumerate(question_texts[i+1:], i+1):
            # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡
            words1 = set(q1.split())
            words2 = set(q2.split())
            common_words = words1.intersection(words2)
            if len(common_words) >= 3 and len(common_words) / len(words1.union(words2)) > 0.6:
                if q1 not in similar_questions:
                    similar_questions[q1] = []
                similar_questions[q1].append(q2)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    report = []
    report.append("=" * 80)
    report.append("ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø© - Ù…Ø§Ø¯Ø© Ø§Ù„Ø£Ø­ÙŠØ§Ø¡ Ù„Ù„ØµÙ Ø§Ù„ØªØ§Ø³Ø¹")
    report.append("=" * 80)
    report.append("")
    report.append("ğŸ¨ ØªØµÙ…ÙŠÙ…: Ø§Ù„ÙˆØªÙŠÙ† Ø§Ù„Ø¶Ø§Ù…Ø±ÙŠØ© | Ù„Ù…Ø§Ø± Ø§Ù„Ø³ÙŠØ§Ø¨ÙŠØ© | Ù…Ù‡Ø§ Ø§Ù„Ù…Ø¹Ù…Ø±ÙŠØ©")
    report.append("         Ù…Ø±ÙŠÙ… Ù…Ø­Ù…ÙˆØ¯ Ø§Ù„Ø¨Ù„ÙˆØ´ÙŠØ© | Ù…Ø±ÙŠÙ… ÙˆØ§Ø¦Ù„ Ø§Ù„Ø¨Ù„ÙˆØ´ÙŠØ© | Ù…Ø±ÙŠÙ… Ø²ÙƒÙŠ Ø§Ù„Ø¹ÙˆÙŠØ³ÙŠØ©")
    report.append("ğŸ« Ù…Ø¯Ø±Ø³Ø© Ø¹Ø§ØªÙƒØ© Ø¨Ù†Øª Ø²ÙŠØ¯")
    report.append("ğŸ‘©â€ğŸ« ØªØ­Øª Ø¥Ø´Ø±Ø§Ù Ø§Ù„Ø£Ø³ØªØ§Ø°Ø© ÙˆÙØ§Ø¡")
    report.append("")
    report.append("=" * 80)
    report.append("")
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
    total_questions = sum(len(questions) for questions in lesson_questions.values())
    report.append("ğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©:")
    report.append("-" * 30)
    report.append(f"ğŸ“š Ø¹Ø¯Ø¯ Ø§Ù„Ø¯Ø±ÙˆØ³: {len(lesson_questions)}")
    report.append(f"â“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©: {total_questions}")
    report.append(f"ğŸ”„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø©: {len(duplicates)}")
    report.append(f"ğŸ“Š Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙØ±ÙŠØ¯Ø©: {len(all_questions)}")
    report.append("")
    
    # ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø©
    if duplicates:
        report.append("ğŸ”„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø©:")
        report.append("=" * 50)
        report.append("")
        
        for i, (question_text, occurrences) in enumerate(duplicates.items(), 1):
            report.append(f"Ø§Ù„ØªÙƒØ±Ø§Ø± Ø±Ù‚Ù… {i}:")
            report.append(f"Ø§Ù„Ø³Ø¤Ø§Ù„: {question_text}")
            report.append("Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ:")
            for lesson, q_num in occurrences:
                report.append(f"  â€¢ {lesson} - Ø§Ù„Ø³Ø¤Ø§Ù„ Ø±Ù‚Ù… {q_num}")
            report.append("-" * 40)
            report.append("")
    else:
        report.append("âœ… Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø³Ø¦Ù„Ø© Ù…ÙƒØ±Ø±Ø©!")
        report.append("")
    
    # ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø©
    if similar_questions:
        report.append("ğŸ” Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø©:")
        report.append("=" * 50)
        report.append("")
        
        for i, (q1, similar_list) in enumerate(similar_questions.items(), 1):
            report.append(f"Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…ØªØ´Ø§Ø¨Ù‡Ø© Ø±Ù‚Ù… {i}:")
            report.append(f"Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: {q1}")
            for similar_q in similar_list:
                report.append(f"Ù…Ø´Ø§Ø¨Ù‡ Ù„Ù€: {similar_q}")
            report.append("-" * 40)
            report.append("")
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙƒÙ„ Ø¯Ø±Ø³
    report.append("ğŸ“š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¯Ø±ÙˆØ³:")
    report.append("=" * 50)
    report.append("")
    
    for lesson_name, questions in lesson_questions.items():
        report.append(f"{lesson_name}: {len(questions)} Ø³Ø¤Ø§Ù„")
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ø±Ø³
        lesson_duplicates = 0
        for q in questions:
            q_text = q['text'].lower().strip()
            if q_text in duplicates:
                lesson_duplicates += 1
        
        if lesson_duplicates > 0:
            report.append(f"  ğŸ”„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ {lesson_duplicates} Ø³Ø¤Ø§Ù„ Ù…ÙƒØ±Ø±")
        else:
            report.append(f"  âœ… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙØ±ÙŠØ¯Ø©")
        report.append("")
    
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    report.append("=" * 80)
    report.append("ğŸ“„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙ‚Ø±ÙŠØ±:")
    report.append("=" * 80)
    report.append(f"ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append(f"ğŸ” Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚: Ù…Ù‚Ø§Ø±Ù†Ø© Ù†ØµÙˆØµ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©")
    report.append(f"ğŸ“Š Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªÙƒØ±Ø§Ø±: {len(duplicates)/len(all_questions)*100:.1f}%")
    report.append("")
    
    # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    report_file = "ØªÙ‚Ø±ÙŠØ±_Ø§Ù„Ø§Ø³Ø¦Ù„Ø©_Ø§Ù„Ù…ÙƒØ±Ø±Ø©.txt"
    
    try:
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))
        
        print("\n" + "=" * 70)
        print("ğŸ‰ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ø¨Ù†Ø¬Ø§Ø­!")
        print(f"ğŸ“ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù: {report_file}")
        print(f"ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
        print(f"   â€¢ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©: {total_questions}")
        print(f"   â€¢ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ÙØ±ÙŠØ¯Ø©: {len(all_questions)}")
        print(f"   â€¢ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø©: {len(duplicates)}")
        print(f"   â€¢ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªÙƒØ±Ø§Ø±: {len(duplicates)/len(all_questions)*100:.1f}%")
        
        if duplicates:
            print("âš ï¸ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ù…ÙƒØ±Ø±Ø© - Ø±Ø§Ø¬Ø¹ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù„Ù„ØªÙØ§ØµÙŠÙ„")
        else:
            print("âœ… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙØ±ÙŠØ¯Ø© - Ù„Ø§ ØªÙˆØ¬Ø¯ ØªÙƒØ±Ø§Ø±Ø§Øª!")
        
        return True
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {e}")
        return False

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    find_duplicate_questions()

if __name__ == "__main__":
    main()